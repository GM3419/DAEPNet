import torch
import torch.nn as nn
import torch.nn.functional as F

class CAFBlock(nn.Module):
    

    参数：
        c : 输入/输出通道数
        reduction : 压缩倍率（默认 2）
        residual_mode : 残差连接方式，'add' 或 'concat'
    """

    def __init__(self, c, reduction=2, residual_mode='concat'):
        super().__init__()
        self.c = c
        self.reduction = reduction
        self.residual_mode = residual_mode

        mid_c = max(1, c // reduction)

        # 通道特征生成
        self.fq = nn.Sequential(
            nn.Conv2d(c, mid_c, kernel_size=1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_c, c, kernel_size=3, padding=1, bias=False)
        )
        self.fk = nn.Sequential(
            nn.Conv2d(c, mid_c, kernel_size=1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_c, c, kernel_size=3, padding=1, bias=False)
        )
        self.fv = nn.Conv2d(c, c, kernel_size=3, padding=1, bias=False)

        # 门控机制
        self.sigmoid_gate = nn.Sigmoid()

        # 如果是 concat 模式，需要降维和匹配 BatchNorm
        if residual_mode == 'concat':
            self.reproject = nn.Conv2d(c * 2, c, kernel_size=1)
            self.bn = nn.BatchNorm2d(c)
        elif residual_mode == 'add':
            self.bn = nn.BatchNorm2d(c)
        else:
            raise ValueError("residual_mode must be 'add' or 'concat'")

        self.relu = nn.ReLU(inplace=True)

    def forward(self, inputs):
        # 获取 query、key、value 特征
        fq = self.fq(inputs)  # [B,C,H,W]
        fk = self.fk(inputs)
        fv = self.fv(inputs)

        # 注意力打分
        f_sim = torch.matmul(fq, fk.transpose(2, 3)) / (fq.size(-1) ** 0.5)
        f_sum = torch.sum(f_sim, dim=(2, 3))  # [B,C]
        softmax_score = torch.softmax(f_sum, dim=1).unsqueeze(2).unsqueeze(3)  # [B,C,1,1]
        gate_score = self.sigmoid_gate(f_sum).unsqueeze(2).unsqueeze(3)

        # 权重融合
        score = softmax_score * gate_score
        out = score * fv

        # 残差连接方式
        if self.residual_mode == 'add':
            r = out + inputs
        else:  # concat 模式
            r = torch.cat([out, inputs], dim=1)
            r = self.reproject(r)

        r = self.bn(r)
        r = self.relu(r)
        return r
